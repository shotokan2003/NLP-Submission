{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 7"
      ],
      "metadata": {
        "id": "_050RaD3JnDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aFl8KaQJAeF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "class NgramAutocomplete:\n",
        "    def __init__(self, n=3):\n",
        "        self.n = n  # N-gram size\n",
        "        self.ngrams = defaultdict(Counter)  # Stores n-grams and their frequencies\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Preprocess the text: Lowercase, remove special characters, and split into words.\"\"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
        "        return text.split()\n",
        "\n",
        "    def train(self, corpus):\n",
        "        \"\"\"Train the model on a corpus of text.\"\"\"\n",
        "        tokens = self.preprocess_text(corpus)\n",
        "        for i in range(len(tokens) - self.n + 1):\n",
        "            prefix = tuple(tokens[i:i + self.n - 1])  # First (n-1) tokens\n",
        "            next_word = tokens[i + self.n - 1]  # nth token\n",
        "            self.ngrams[prefix][next_word] += 1  # Increment frequency\n",
        "\n",
        "    def predict_next(self, context, top_k=3):\n",
        "        \"\"\"Predict the next word given a context of (n-1) words.\"\"\"\n",
        "        context = tuple(self.preprocess_text(context)[-self.n + 1:])  # Use last (n-1) words\n",
        "        if context in self.ngrams:\n",
        "            # Get the most probable next words\n",
        "            predictions = self.ngrams[context].most_common(top_k)\n",
        "            return [word for word, _ in predictions]\n",
        "        else:\n",
        "            return []  # No prediction available for unseen context\n",
        "\n",
        "    def generate_text(self, start_text, max_words=20):\n",
        "        \"\"\"Generate text starting with a given phrase.\"\"\"\n",
        "        generated = self.preprocess_text(start_text)\n",
        "        for _ in range(max_words):\n",
        "            context = tuple(generated[-self.n + 1:])  # Use last (n-1) words as context\n",
        "            next_word = self.predict_next(' '.join(context), top_k=1)\n",
        "            if not next_word:\n",
        "                break  # Stop if no next word is predicted\n",
        "            generated.append(next_word[0])\n",
        "        return ' '.join(generated)\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training corpus\n",
        "    corpus = \"\"\"\n",
        "    Machine learning is a field of artificial intelligence that uses algorithms to learn from data.\n",
        "    Natural language processing is a subfield of machine learning.\n",
        "    Auto-complete systems rely on predictive models.\n",
        "    \"\"\"\n",
        "\n",
        "    model = NgramAutocomplete(n=3)  # Create a trigram model\n",
        "    model.train(corpus)  # Train on the corpus\n",
        "\n",
        "    # Predictions\n",
        "    context = \"machine learning is\"\n",
        "    predictions = model.predict_next(context)\n",
        "    print(f\"Predictions for '{context}': {predictions}\")\n",
        "\n",
        "    # Generate text\n",
        "    start_text = \"machine learning\"\n",
        "    generated_text = model.generate_text(start_text, max_words=10)\n",
        "    print(f\"Generated text: {generated_text}\")\n"
      ]
    }
  ]
}